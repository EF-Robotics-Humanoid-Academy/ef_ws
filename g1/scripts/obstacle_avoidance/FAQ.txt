================================================================================
  FAQ -- Obstacle-Avoidance Navigation for the Unitree G1
  Directory: g1/scripts/obstacle_avoidance/
================================================================================

Contents
--------
  1.  What does this system do?
  2.  Which files make up the system and what does each one do?
  3.  What hardware / software prerequisites are needed?
  4.  How do I run the navigator?
  5.  What CLI arguments does navigate.py accept?
  6.  What is the occupancy grid and how is it stored?
  7.  How does world-to-grid coordinate conversion work?
  8.  How are obstacles detected?
  9.  What is range_obstacle[4] and how is it mapped to directions?
 10.  How does A* pathfinding work in this system?
 11.  What is path smoothing and why is it needed?
 12.  How are grid-cell paths converted to real-world waypoints?
 13.  How does the proportional locomotion controller work?
 14.  What is the walk_to control loop doing each tick?
 15.  What happens when an obstacle is detected mid-walk?
 16.  How does dynamic replanning work end-to-end?
 17.  What is obstacle inflation and why is it used?
 18.  How does the live map viewer work?
 19.  Can I run the map viewer without commanding the robot to move?
 20.  How is thread safety handled?
 21.  What SDK APIs does this system use?
 22.  What network / interface setup is required?
 23.  How do I tune the control parameters?
 24.  What are the known limitations?
 25.  How do I save and reload a map?
 26.  Can I pre-populate the map with known obstacles?
 27.  How do I run the self-tests?
 28.  What dependencies need to be installed?
 29.  What would I change for simulation vs. real robot?
 30.  What are good next steps / improvements?
 31.  How does SLAM mapping + mouse picking work?


================================================================================
1. What does this system do?
================================================================================

It makes the Unitree G1 humanoid robot navigate autonomously from its current
position to a user-specified goal (x, y) in metres, while avoiding obstacles
discovered at runtime.

The pipeline:
  1. Connect to the robot over Ethernet via Unitree SDK2 Python.
  2. Build (or load) a 2D occupancy grid map.
  3. Plan a shortest path using A* on the grid.
  4. Smooth the path and divide it into ~0.5 m waypoints.
  5. Walk the robot toward each waypoint using proportional control.
  6. At every control tick (~10 Hz), check for obstacles via range_obstacle.
  7. If an obstacle blocks the front, stop, add it to the map, and replan.
  8. Repeat until the goal is reached or max replans are exhausted.


================================================================================
2. Which files make up the system and what does each one do?
================================================================================

  create_map.py        OccupancyGrid class -- 2D numpy grid with worldâ†”grid
                       coordinate conversion, obstacle marking from sensor
                       ranges, inflation (scipy), save/load as .npz.

  path_planner.py      A* pathfinding on a 2D grid.  Also: Bresenham
                       line-of-sight path smoothing and grid-to-world
                       waypoint conversion with configurable spacing.

  obstacle_detection.py
                       ObstacleDetector class -- subscribes to the DDS topic
                       "rt/sportmodestate" to read the robot's pose
                       (position + yaw) and range_obstacle[4] distances.
                       Thread-safe via threading.Lock.

  locomotion.py        Locomotion class -- proportional-control walk_to()
                       that drives the robot toward a waypoint using
                       LocoClient.Move().  Accepts a check_obstacle callback.

  navigate.py          Main orchestrator.  Parses CLI args, initialises the
                       SDK, wires all modules together, runs the navigation
                       loop with dynamic replanning.

  map_viewer.py        MapViewer class -- real-time OpenCV visualisation of
                       the occupancy grid, robot pose, trail, planned path,
                       waypoints, goal, and range sensor lines.  Can run
                       standalone or integrated via --viz flag.


================================================================================
3. What hardware / software prerequisites are needed?
================================================================================

Hardware:
  - Unitree G1 humanoid robot, powered on and standing (FSM state 200).
  - Ethernet connection between the host PC and the robot.
    The robot is at 192.168.123.161 on the 192.168.123.0/24 subnet.

Software (Python packages):
  - unitree_sdk2py     (pip install -e <path-to-unitree_sdk2_python>)
  - numpy
  - scipy              (for binary_dilation in obstacle inflation)
  - opencv-python      (cv2, needed only if using --viz or map_viewer.py)

The system does NOT use ROS.  Communication is via CycloneDDS (domain 0)
through the unitree_sdk2py library.


================================================================================
4. How do I run the navigator?
================================================================================

Minimal example -- walk 3 metres forward on X:

Note: navigate.py now uses safety/hanger_boot_sequence.py to ensure the
robot is in FSM-200 before sending motion commands.

    python navigate.py --iface eth0 --goal_x 3.0 --goal_y 0.0

With live visualisation:

    python navigate.py --iface eth0 --goal_x 3.0 --goal_y 2.0 --viz

With a specific final heading (face +Y = pi/2):

    python navigate.py --iface eth0 --goal_x 5.0 --goal_y 0.0 --goal_yaw 1.57

Loading a previously saved map:

    python navigate.py --iface eth0 --goal_x 3.0 --goal_y 2.0 --load_map saved.npz


================================================================================
5. What CLI arguments does navigate.py accept?
================================================================================

  --iface        Network interface (default: eth0)
  --goal_x       Goal X in metres (required)
  --goal_y       Goal Y in metres (required)
  --goal_yaw     Final heading in radians (optional)
  --map_width    Map width in metres (default: 10.0)
  --map_height   Map height in metres (default: 10.0)
  --resolution   Metres per grid cell (default: 0.1)
  --load_map     Path to a .npz map file to load instead of creating empty
  --max_speed    Maximum forward speed in m/s (default: 0.3)
  --inflation    Obstacle inflation radius in cells (default: 3)
  --spacing      Waypoint spacing in metres (default: 0.5)
  --max_replans  Max replan attempts before giving up (default: 20)
  --viz          Show a live OpenCV map window while navigating


================================================================================
6. What is the occupancy grid and how is it stored?
================================================================================

The occupancy grid is a 2D numpy array of dtype int8:
  - 0 = free cell
  - 1 = obstacle cell

Internally it is stored as:
  grid.shape = (height_cells, width_cells)   i.e. grid[row, col]

where:
  row = index along the Y-axis (world Y increases with row)
  col = index along the X-axis (world X increases with col)

The grid also stores:
  - resolution: metres per cell (default 0.1 m)
  - origin: world coordinates (x, y) of cell (row=0, col=0)

For a default 10x10 m map at 0.1 m resolution the grid is 100x100 cells,
with the origin at (-5.0, -5.0) so the robot starts near the centre.

Serialisation uses numpy's .npz format:
  - grid: the int8 array
  - resolution: float64
  - origin_x, origin_y: float64


================================================================================
7. How does world-to-grid coordinate conversion work?
================================================================================

  World (wx, wy) --> Grid (row, col):
      col = int((wx - origin_x) / resolution)
      row = int((wy - origin_y) / resolution)
      Both are clamped to [0, dimension - 1].

  Grid (row, col) --> World (wx, wy):
      wx = col * resolution + origin_x + resolution / 2
      wy = row * resolution + origin_y + resolution / 2
      (Returns the cell centre.)

This means:
  - X maps to columns, Y maps to rows.
  - Increasing row = increasing world Y.
  - Increasing col = increasing world X.


================================================================================
8. How are obstacles detected?
================================================================================

The ObstacleDetector subscribes to the DDS topic "rt/sportmodestate" which
publishes SportModeState_ messages at high frequency from the robot's onboard
controller.

The relevant fields are:
  - position[3]:      (x, y, z) in metres, world frame.
  - imu_state.rpy[3]: (roll, pitch, yaw) in radians.
  - range_obstacle[4]: distances (metres) to nearest obstacle in 4 directions.

The detector classifies each range reading as:
  - BLOCKED if distance < stop_distance (default 0.4 m)
  - WARNING if distance < warn_distance (default 0.8 m)

The navigation loop calls detector.front_blocked() each tick.  If True, the
robot stops and the orchestrator replans.


================================================================================
9. What is range_obstacle[4] and how is it mapped to directions?
================================================================================

range_obstacle is a 4-element array from SportModeState_.  The assumed
mapping (verify empirically on the real robot):

  Index   Direction        Angle offset from yaw
  -----   ---------        ---------------------
    0     Front            0
    1     Right           -pi/2
    2     Rear             pi
    3     Left            +pi/2

Values <= 0.01 m or >= 5.0 m are treated as invalid / out-of-range and
are skipped.

The world position of a detected obstacle is computed as:
    obs_x = robot_x + distance * cos(robot_yaw + offset)
    obs_y = robot_y + distance * sin(robot_yaw + offset)


================================================================================
10. How does A* pathfinding work in this system?
================================================================================

The astar() function in path_planner.py implements standard A* on a 2D grid:

  - Input: numpy grid (0=free, nonzero=blocked), start (row,col), goal (row,col)
  - 8-connected by default (diagonal moves allowed at cost sqrt(2))
  - Heuristic: Euclidean distance (admissible for 8-connected grid)
  - Data structures: heapq priority queue, dict for g_scores and came_from
  - Returns: list of (row,col) from start to goal inclusive, or None

Guard checks:
  - Start or goal out of bounds -> None
  - Start or goal is an obstacle cell -> None

The search runs on the INFLATED grid, not the raw occupancy grid, so the
planned path keeps a safety margin from obstacles.


================================================================================
11. What is path smoothing and why is it needed?
================================================================================

Raw A* paths on a grid follow cell edges and corners, producing many small
zig-zag segments.  smooth_path() reduces unnecessary waypoints using greedy
Bresenham line-of-sight checks:

  1. Start from the first cell in the path.
  2. Try to skip up to max_skip=5 cells ahead.
  3. Check if the direct Bresenham line between current and candidate is
     entirely free (all cells = 0).
  4. If so, skip the intermediate cells.
  5. Repeat until the end of the path.

This produces a path with fewer, straighter segments, which translates to
fewer waypoints and smoother robot motion.


================================================================================
12. How are grid-cell paths converted to real-world waypoints?
================================================================================

grid_path_to_world_waypoints() converts (row,col) paths to (x,y) metre
coordinates and sub-samples them at a configurable spacing (default 0.5 m):

  1. Convert every grid cell to world coordinates using grid_to_world().
  2. Walk along the world-coordinate path, accumulating segment lengths.
  3. Every time the accumulated distance reaches spacing_m, emit a waypoint.
  4. Always include the first and last points.

For a 3 m path with spacing 0.5 m, this produces roughly 7 waypoints.


================================================================================
13. How does the proportional locomotion controller work?
================================================================================

The Locomotion class uses a simple proportional (P) controller:

  1. Compute vector from robot to target: (dx, dy) = target - current_pos
  2. Distance = hypot(dx, dy)
  3. Target heading = atan2(dy, dx)
  4. Heading error = wrap_angle(target_heading - current_yaw)

  If |heading_error| > yaw_tolerance (0.15 rad ~ 8.6 deg):
      Turn in place:  vx = 0,  vyaw = Kp_yaw * heading_error

  Otherwise:
      Move forward:   vx = Kp_lin * distance,  vyaw = Kp_yaw * heading_error

  All velocities are clamped:
      vx   in [0, max_vx]       (default max_vx = 0.3 m/s)
      vyaw in [-max_vyaw, +max_vyaw]  (default max_vyaw = 0.5 rad/s)

The robot is considered "arrived" when distance < position_tolerance (0.2 m).

If a final_yaw is specified, the robot turns in place after arriving.


================================================================================
14. What is the walk_to control loop doing each tick?
================================================================================

At each tick (default 0.1 s = 10 Hz):

  1. Check timeout -- if exceeded, stop and return False.
  2. Read pose from ObstacleDetector.get_pose().
  3. Compute distance and heading error to target.
  4. If distance < tolerance: stop, optionally turn to final_yaw, return True.
  5. Compute vx and vyaw using proportional control.
  6. Send Move(vx, 0.0, vyaw, continous_move=True) to LocoClient.
  7. Call check_obstacle() callback -- if it returns True: stop, return False.
  8. Sleep for tick duration.

The check_obstacle callback is how navigate.py injects both obstacle checking
AND map viewer updates into the locomotion loop without coupling the modules.


================================================================================
15. What happens when an obstacle is detected mid-walk?
================================================================================

  1. check_obstacle() (or _check_and_viz in navigate.py) returns True.
  2. walk_to() calls StopMove() and returns False.
  3. navigate.py breaks out of the waypoint loop, sets aborted=True.
  4. It reads the obstacle positions from detector.get_obstacle_world_positions()
     and adds them to the occupancy grid via set_obstacle_world().
  5. It increments the replan counter.
  6. The outer while-loop starts a new planning iteration with the updated map.


================================================================================
16. How does dynamic replanning work end-to-end?
================================================================================

  Step 1: Get current pose from ObstacleDetector.
  Step 2: Mark obstacles on the map using range_obstacle readings.
  Step 3: Inflate the map (dilate obstacles by N cells for safety margin).
  Step 4: Convert current pose and goal to grid cells.
  Step 5: Run A* on the inflated grid.
  Step 6: Smooth the path and generate world-coordinate waypoints.
  Step 7: Walk each waypoint with obstacle checking.
  Step 8: If blocked -> add new obstacles to map -> go to Step 1.

This repeats up to max_replans (default 20) times.  The map accumulates
all discovered obstacles across replans, so the robot won't try the same
blocked route twice.


================================================================================
17. What is obstacle inflation and why is it used?
================================================================================

Inflation dilates every obstacle cell outward by N cells in all directions
using scipy.ndimage.binary_dilation with a square kernel of size (2N+1).

With default inflation=3 and resolution=0.1 m, each obstacle is expanded
by 0.3 m in every direction.  This means:
  - A* paths stay at least 0.3 m away from any obstacle.
  - The robot (which has a physical width) is less likely to clip corners.

Inflation is applied to a COPY of the grid -- the raw grid retains only
the actual obstacle cells.  This way new sensor readings are recorded
precisely, and inflation is recomputed each planning cycle.


================================================================================
18. How does the live map viewer work?
================================================================================

map_viewer.py uses OpenCV (cv2.imshow) to render a colour image of the map:

Layer (bottom to top):
  1. White background = free cells.
  2. Light grey = inflated obstacle zones.
  3. Dark grey/black = actual obstacle cells.
  4. Faint green line = robot trail (past positions).
  5. Light blue line = planned path (from A* + smoothing).
  6. Blue dots = waypoints.
  7. Red star = goal position.
  8. Coloured lines from robot = range sensor readings:
       green = range > 0.8 m (OK)
       orange = 0.4 m < range < 0.8 m (warning)
       red = range < 0.4 m (blocked)
  9. Green circle + arrow = robot position and heading.
 10. HUD text = position, yaw, obstacle count, trail length.

The viewer is refreshed at control-loop rate (~10 Hz) via the
_check_and_viz() callback injected into walk_to().

Grid cells are scaled up by a factor (default 4) so a 100x100 grid
becomes a 400x400 pixel window.

The display uses a Y-flip so that world-Y increases upward (standard
cartesian), even though OpenCV images have Y increasing downward.


================================================================================
19. Can I run the map viewer without commanding the robot to move?
================================================================================

Yes.  Run it standalone:

    python map_viewer.py eth0

This connects to the robot, subscribes to SportModeState_, and builds a
live obstacle map as the robot reports range_obstacle data.  The robot does
NOT receive any Move commands -- it is observation only.

Press 'q' or ESC to quit.  The map is saved to /tmp/live_obstacle_map.npz.


================================================================================
20. How is thread safety handled?
================================================================================

The Unitree SDK2 DDS subscriber callback runs on an internal SDK thread,
NOT on the main Python thread.  ObstacleDetector protects all shared state
with a single threading.Lock:

  - _lock protects: _position, _velocity, _rpy, _range_obstacle, _last_update
  - Every getter (get_pose, get_ranges, etc.) acquires the lock.
  - The DDS callback (_on_sportmode_state) acquires the lock to write.

This ensures the main thread always reads a consistent snapshot of the
robot's state, even though the DDS callback fires asynchronously.


================================================================================
21. What SDK APIs does this system use?
================================================================================

  ChannelFactoryInitialize(domain_id, interface)
      Initialise the CycloneDDS communication layer.
      domain_id = 0 for real robot, 1 for simulation.

  LocoClient (unitree_sdk2py.g1.loco.g1_loco_client)
      .Init()               -- connect to the "sport" RPC service
      .SetTimeout(seconds)   -- RPC timeout
      .Move(vx, vy, vyaw, continous_move=True)
                             -- velocity command (m/s, m/s, rad/s)
      .StopMove()            -- zero velocity, let robot stand

  ChannelSubscriber (unitree_sdk2py.core.channel)
      Subscribe to "rt/sportmodestate" with SportModeState_ message type.

  SportModeState_ (unitree_sdk2py.idl.unitree_go.msg.dds_)
      .position[3]           -- (x, y, z) metres
      .velocity[3]           -- (vx, vy, vz) m/s
      .imu_state.rpy[3]      -- (roll, pitch, yaw) radians
      .range_obstacle[4]     -- obstacle distances (metres)

Note: the robot must be in FSM state 200 (standing) before sending Move
commands.  Use Damp() or StandUp() via LocoClient if needed.


================================================================================
22. What network / interface setup is required?
================================================================================

  1. Connect to the robot via Ethernet.
  2. Configure your PC's interface on the 192.168.123.0/24 subnet:
         sudo ip addr add 192.168.123.100/24 dev eth0
         sudo ip link set eth0 up
  3. Verify connectivity:
         ping 192.168.123.161
  4. Pass the interface name to navigate.py:
         python navigate.py --iface eth0 ...

The SDK uses CycloneDDS under the hood.  Domain ID 0 is the real robot's
domain.  ChannelFactoryInitialize must be called exactly once per process.


================================================================================
23. How do I tune the control parameters?
================================================================================

Locomotion (locomotion.py):
  Kp_lin = 0.8           Proportional gain for forward speed.
                          Higher = more aggressive approach to waypoints.
  Kp_yaw = 1.5           Proportional gain for yaw correction.
                          Higher = faster turning.
  max_vx = 0.3 m/s       Top forward speed. The G1 walks comfortably
                          at 0.2-0.4 m/s.  Do not exceed ~0.5.
  max_vyaw = 0.5 rad/s   Top yaw rate.
  position_tolerance      Distance (m) to declare "arrived" at a waypoint.
      = 0.2 m             Smaller = more precise but slower.
  yaw_tolerance           Heading error (rad) below which the robot moves
      = 0.15 rad          forward instead of turning in place (~8.6 deg).

Obstacle detection (obstacle_detection.py):
  warn_distance = 0.8 m  Below this, range is flagged as WARNING.
  stop_distance = 0.4 m  Below this, front_blocked() returns True.

Navigation (navigate.py CLI):
  --inflation = 3 cells   Safety margin around obstacles (0.3 m at 0.1 res).
  --spacing = 0.5 m       Distance between successive waypoints.
  --max_speed = 0.3 m/s   Forwarded to Locomotion as max_vx.
  --max_replans = 20      Give up after this many obstacle-triggered replans.

Tips:
  - If the robot clips corners, increase --inflation.
  - If the robot is too slow, increase --max_speed (carefully).
  - If waypoints are overshot, decrease --spacing or Kp_lin.
  - If the robot oscillates in heading, decrease Kp_yaw.


================================================================================
24. What are the known limitations?
================================================================================

  1. Range-only obstacle sensing.  The system uses range_obstacle[4] which
     gives only 4 distance readings (front/right/rear/left).  Obstacles
     between these directions can be missed.

  2. No LiDAR integration.  The Livox MID-360 on the G1 uses a separate
     SDK (livox_python), not unitree_sdk2py.  Integrating it would give
     360-degree obstacle detection but requires additional setup.

  3. 2D only.  The occupancy grid is flat.  Steps, ramps, and overhanging
     obstacles are not modelled.

  4. No localisation drift correction.  The robot's position comes from
     the onboard state estimator which drifts over time.  There is no
     SLAM loop-closure or external reference.

  5. Static goal.  The goal is set once via CLI arguments.  There is no
     dynamic goal selection or multi-goal waypoint following.

  6. Proportional control only.  No PID, no trajectory tracking.  Works
     well for slow speeds but may overshoot at higher velocities.

  7. No reverse motion.  The controller always faces the target and walks
     forward.  The robot never walks backward.

  8. Grid boundary.  If the robot drifts outside the map bounds, world
     coordinates are clamped to the nearest edge cell, which can cause
     incorrect planning.

  9. Obstacle persistence.  Once a cell is marked as obstacle, it is never
     cleared.  Moving obstacles (people, doors) leave permanent marks.

 10. Map viewer requires a display.  The --viz flag needs a graphical
     environment (X11, Wayland, etc.).  It will fail over pure SSH without
     X forwarding.


================================================================================
25. How do I save and reload a map?
================================================================================

Maps are saved automatically on exit to /tmp/final_obstacle_map.npz (or
/tmp/live_obstacle_map.npz for standalone map_viewer).

To reload a saved map:

    python navigate.py --iface eth0 --goal_x 3.0 --goal_y 2.0 \
        --load_map /tmp/final_obstacle_map.npz

The .npz file contains:
  - grid:      int8 array (H x W)
  - resolution: float64
  - origin_x:  float64
  - origin_y:  float64

You can also load and inspect a map in Python:

    from create_map import OccupancyGrid
    m = OccupancyGrid.load("my_map.npz")
    print(m.grid.shape, m.resolution, m.origin)


================================================================================
26. Can I pre-populate the map with known obstacles?
================================================================================

Yes.  Create a map in Python, add obstacles, and save it:

    from create_map import OccupancyGrid

    m = OccupancyGrid(10.0, 10.0, 0.1, -5.0, -5.0)

    # Add a wall from (1.0, -1.0) to (1.3, 1.0)
    m.add_rectangle(1.0, -1.0, 1.3, 1.0)

    # Add a single obstacle point
    m.set_obstacle_world(2.5, 0.3)

    m.save("my_map.npz")

Then load it:

    python navigate.py --iface eth0 --goal_x 5.0 --goal_y 0.0 \
        --load_map my_map.npz

New obstacles detected at runtime will be added on top of the pre-loaded map.


================================================================================
27. How do I run the self-tests?
================================================================================

create_map.py and path_planner.py have __main__ self-test blocks:

    cd g1/scripts/obstacle_avoidance/
    python create_map.py
    python path_planner.py

Expected output for create_map.py:
    Grid: 100x100 cells, resolution=0.1m
    Obstacles after adding wall: ... cells
    World (0,0) -> grid (50,50) -> world (0.05,0.05)
    Obstacles after range marking: ... cells
    Inflated obstacles: ... cells
    Save/load round-trip: OK
    All tests passed.

Expected output for path_planner.py:
    A* found path with ... cells
    Smoothed to ... waypoints
    Clear grid path: ... cells
    Blocked grid: No path (correct)
    All tests passed.

obstacle_detection.py and locomotion.py also have __main__ blocks, but
they require a live robot connection:

    python obstacle_detection.py eth0     # prints live range/pose data
    python locomotion.py eth0             # walks robot 1 m forward


================================================================================
28. What dependencies need to be installed?
================================================================================

Core (required):
    pip install numpy scipy

    # Unitree SDK2 Python (from source)
    pip install -e /path/to/unitree_sdk2_python

Visualisation (optional, for --viz):
    pip install opencv-python

The CycloneDDS library (version 0.10.2) is installed as a dependency of
unitree_sdk2py.


================================================================================
29. What would I change for simulation vs. real robot?
================================================================================

The only change is the DDS domain ID in ChannelFactoryInitialize:

    Real robot:   ChannelFactoryInitialize(0, "eth0")
    Simulation:   ChannelFactoryInitialize(1, "lo")

In navigate.py this is currently hardcoded to domain 0 (real robot).
To switch, change line 101 or add a --sim CLI flag.

The simulation must publish SportModeState_ on "rt/sportmodestate" and
accept Move commands on the LocoClient RPC service for the system to work.


================================================================================
30. What are good next steps / improvements?
================================================================================

  - LiDAR integration:  Use the Livox MID-360 for full 360-degree obstacle
    detection instead of the 4-direction range_obstacle.

  - SLAM:  Integrate KISS-ICP or similar to correct odometry drift and
    produce more accurate maps over longer distances.

  - Dynamic obstacle clearing:  Age-out or decay obstacle cells that
    haven't been re-confirmed, so moving obstacles don't leave permanent
    marks.

  - PID controller:  Replace proportional-only control with PID for
    smoother trajectory tracking at higher speeds.

  - Multi-goal navigation:  Accept a sequence of goals or integrate with
    a task planner.

  - 3D occupancy (voxel grid):  Model vertical obstacles like steps,
    tables, and overhangs.

  - Camera-based detection:  Use the RealSense depth camera or the
    CLIP-based object detector (see ../obj_detection/) to recognise
    specific objects as obstacles or targets.

  - RViz/web visualisation:  Replace the OpenCV viewer with a web-based
    dashboard for remote monitoring without X11 forwarding.

  - Recovery behaviours:  If no path is found, try backing up, rotating
    in place, or requesting human assistance.

================================================================================


================================================================================
31. How does SLAM mapping + mouse picking work?
================================================================================

navigate.py now prefers the built-in utlidar SLAM map (HeightMap_ on
"rt/utlidar/map_state") as the occupancy grid. It converts height values into
obstacles using a configurable threshold (see --slam-height-threshold).

At startup, navigate.py opens the map viewer and lets you click START and
GOAL directly on the map:
  - Left click: set START, then GOAL.
  - Right click: reset selections.
  - Press 'c' or Enter to confirm.

Safety notes:
  - The robot pose is still taken from SportModeState_. If you click a start
    point far from the robot (>0.5 m), the planner will warn and use the
    robot's actual pose instead.
  - The navigation loop continues to use range_obstacle for immediate
    near-field avoidance while following the SLAM-derived map.

